# Redis 学习笔记
 在日常开发过程中，无不都是使用数据库进行操作的存储，由于一般的系统任务中不会存在高并发的情况，当遇到主页访问量增大时，磁盘的读写速度慢而存在严重的弊端。  
 NoSql技术就是克服以上问题而引入的，这是一种基于内存的数据库，并且提供一定的持久化功能。  
 Redis和MongoDB是当前使用的最广泛的NoSql技术，而就Redis而言，它的性能十分优越，可以支持十几万次的读写操纵，还支持集群，分布式，主从同步等配置。
 ## 三大特点
       1.Redis 支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用
       
       2.Redis 不仅仅支持简单的 key-value 类型的数据，同时还提供 list，set，zset，hash 等数据结构的存储
       
       3.Redis 支持数据的备份，即 master-slave(主从) 模式的数据备份
       
 ## Redis 优势
       1.性能极高 – Redis 能读的速度是 110000 次/s,写的速度是 81000 次/s
       
       2.丰富的数据类型 – Redis 支持二进制案例的 Strings, Lists, Hashes, Sets 及Ordered Sets 数据类型操作
       
       3.原子 – Redis 的所有操作都是原子性的，意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过 MULTI 和 EXEC指令包起来
       
       4.丰富的特性 – Redis 还支持 publish/subscribe, 通知, key 过期等等特性
 ## Redis应用场景--数据类型
 ### string类型
 作为常规的key-value缓存应用，主要是用于计数使用，例如微博数，粉丝数等  
 **注：一个键的最大值是512mb**
 ### hash类型
 redis hash是一个string类型的field和value的映射表，hash特别适用于存储对象（因为对象可以包含多种属性）  
 常用命令:hget hset hgetall  
 **主要用来存储对象信息**  
 ### list类型
 list只是简单字符串列表，按照插入的顺序进行排序（由LinkedList内部实现），可以选择将一个链表插入到头部或者尾部  
 常用命令 :lpush（添加左边元素）,rpush,lpop（移除左边第一个元素）,rpop,lrange（获取列表片段，LRANGE key start stop）等  
 应用场景：Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如twitter的关注列表，粉丝列表等都可以用Redis的list结构来实现
 ### set类型
 对外提供的是与list相同的一个列表功能，特殊之处在于set可以自动去重，set提供了判断某个元素是否在set集合内，可以基于set轻易实现交集，并集，差集等操作  
 应用场景：在微博中，可以将一个用户所有的关注人存在一个集合中，将其所有粉丝存在一个set集合，可以非常方便的实现如共同关注、共同喜好、二度好友等功能，对上面的所有集合操作，你还可以使用不同的命令选择将结果返回给客户端还是存集到一个新的集合中
 ### zset类型（sorted set）
 Redis sorted set的内部使用HashMap和跳跃表(SkipList)来保证数据的存储和有序。zset相对于set增加了一个score的权重参数，HashMap里放的是成员到score的映射，跳跃表按score从小到大保存所有集合元素。使用跳跃表的结构可以获得比较高的查找效率，并且在实现上比较简单。时间复杂度与红黑树相同O(logn)，增加、删除的操作较为简单  
 应用场景：排行榜
 ## Redis应用场景--特殊数据类型
 ### Bitmaps
 现代计算机用二进制（位） 作为信息的基础单位， 1个字节等于8位， 例如“big”字符串是由3个字节组成， 但实际在计算机存储时将其用二进制表示， “big”分别对应的ASCII码分别是98、 105、 103， 对应的二进制分别是01100010、 01101001和01100111  
 ![字符串二进制表示](image/1.png)  
 许多开发语言都提供了操作位的功能， 合理地使用位能够有效地提高内存使用率和开发效率。 Redis提供了Bitmaps这个"**数据结构**"可以实现对位的操作  
 **注意:**  
       1.Bitmaps本身不是一种数据结构， 实际上它就是字符串， 但是它可以对字符串的位进行操作。  
       2.Bitmaps单独提供了一套命令， 所以在Redis中使用Bitmaps和使用字符串的方法不太相同。**可以把Bitmaps想象成一个以位为单位的数组， 数组的每个单元只能存储0和1， 数组的下标在Bitmaps中叫做偏移量**
  #### Bitmaps 设置值
  ``setbit key offset value``   
  设置键的第offset个位的值（**从0算起,值只能为0或1**），假设现在有20个用户，userid=0， 5， 11， 15， 19的用户对网站进行了访问, 那么当前Bitmaps初始化结果如下图  
  ![设置值](image/2.png)  
  具体操作过程如下， unique： users： 2016-04-05代表2016-04-05这天的独立访问用户的Bitmaps  
 ```
127.0.0.1:6379> setbit unique:users:2016-04-05 0 1
(integer) 0
127.0.0.1:6379> setbit unique:users:2016-04-05 5 1
(integer) 0
127.0.0.1:6379> setbit unique:users:2016-04-05 11 1
(integer) 0
127.0.0.1:6379> setbit unique:users:2016-04-05 15 1
(integer) 0
127.0.0.1:6379> setbit unique:users:2016-04-05 19 1
(integer) 0
```
 #### Bitmaps 获取值
 ``getbit key offset``  
 获取键的第offset位的值（从0开始算,**不存在的offset返回值也为0**） ， 例:下面操作获取id=8的用户是否在2016-04-05这天访问过， 返回0说明没有访问过
 ```
127.0.0.1:6379> getbit unique:users:2016-04-05 8
(integer) 0
```
  #### Bitmaps 获取指定范围内的个数
  ``bitcount [start][end]``  
  下面操作计算2016-04-05这天的独立访问用户数量：  
  ```
127.0.0.1:6379> bitcount unique:users:2016-04-05
(integer) 5
```
  \[start]以及\[end]代表的是开始字节以及结束字节(**字节占8位**),下面操作计算用户id在第1个字节到第3个字节之间的独立访问用户数， 对应的用户id是11， 15， 19
  ```
127.0.0.1:6379> bitcount unique:users:2016-04-05 1 3
(integer) 3
```
 #### Bitmaps 分析
 假设网站有1亿用户， 每天独立访问的用户有5千万， 如果每天用集合类型和Bitmaps分别存储活跃用户可以得到如下图所示的表  
 ![分析表-1](image/3.png)  
 很明显,在活跃用户较大的情况下,那么使用Bitmaps能够节约足够多的空间,且查询速度也更加快速  
 **当用户活跃数少的时候,反而使用集合类型更加节约空间**  
 ![分析表-2](image/4.png)
 ### HyperLogLog
 HyperLogLog算法是一种非常巧妙的近似统计海量去重元素数量的算法。它内部维护了 16384 个桶（bucket）来记录各自桶的元素数量。当一个元素到来时，它会散列到其中一个桶，以一定的概率影响这个桶的计数值。因为是概率算法，所以单个桶的计数值并不准确，但是将所有的桶计数值进行调合均值累加起来，结果就会非常接近真实的计数值  
 ![HyperLogLog](image/5.jpeg)  
 **举个例子：**  
 >假如我要统计网页的UV（浏览用户数量，一天内同一个用户多次访问只能算一次），传统的解决方案是使用Set来保存用户id，然后统计Set中的元素数量来获取页面UV。但这种方案只能承载少量用户，一旦用户数量大起来就需要消耗大量的空间来存储用户id。我的目的是统计用户数量而不是保存用户，这简直是个吃力不讨好的方案！而使用Redis的HyperLogLog最多需要12k就可以统计大量的用户数，尽管它大概有0.81%的错误率，但对于统计UV这种不需要很精确的数据是可以忽略不计的
 #### HyperLogLog 基数统计
 一个集合（注意：这里集合的含义是 Object 的聚合，可以包含重复元素）中不重复元素的个数。例如集合 {1,2,3,1,2}，它有5个元素，但它的基数/Distinct 数为3  
 Redis 最常用的数据结构有字符串、列表、字典、集合和有序集合。后来，由于 Redis 的广泛应用，Redis 自身也做了很多补充，其中就有 HyperLogLog（2.8.9 版本添加）结构。HyperLogLog 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常大时，计算基数所需的空间总是固定的、并且是很小的  
 #### Redis HyperLogLog结构
 在 Redis 中每个键占用的内容都是 12K，理论存储近似接近 2^64 个值，不管存储的内容是什么。这是一个基于基数估计的算法，只能比较准确的估算出基数，可以使用少量固定的内存去存储并识别集合中的唯一元素。但是这个估算的基数并不一定准确，是一个带有 0.81% 标准错误（standard error）的近似值  
 **但是，也正是因为只有 12K 的存储空间，所以，它并不实际存储数据的内容**
 #### Redis HyperLogLog命令
 ##### PFADD 命令
 将任意数量的元素添加到指定的 HyperLogLog 里面。时间复杂度： 每添加一个元素的复杂度为 O(1) 。如果 HyperLogLog 估计的近似基数（approximated cardinality）在命令执行之后出现了变化， 那么命令返回 1 ， 否则返回 0 。 如果命令执行时给定的键不存在， 那么程序将先创建一个空的 HyperLogLog 结构， 然后再执行命令  
 ```
 # 命令格式：PFADD key element [element …]
 # 如果给定的键不存在，那么命令会创建一个空的 HyperLogLog，并向客户端返回 1
 127.0.0.1:6379> PFADD ip_20190301 "192.168.0.1" "192.168.0.2" "192.168.0.3"
 (integer) 1
 # 元素估计数量没有变化，返回 0（因为 192.168.0.1 已经存在）
 127.0.0.1:6379> PFADD ip_20190301 "192.168.0.1"
 (integer) 0
 # 添加一个不存在的元素，返回 1。注意，此时 HyperLogLog 内部存储会被更新，因为要记录新元素
 127.0.0.1:6379> PFADD ip_20190301 "192.168.0.4"
 (integer) 1
```
 ##### PFCOUNT 命令
 当 PFCOUNT key [key …] 命令作用于单个键时，返回储存在给定键的 HyperLogLog 的近似基数，如果键不存在，那么返回 0，复杂度为 O(1)，并且具有非常低的平均常数时间;  
 当 PFCOUNT key [key …] 命令作用于多个键时，返回所有给定 HyperLogLog 的并集的近似基数，这个近似基数是通过将所有给定 HyperLogLog 合并至一个临时 HyperLogLog 来计算得出的，复杂度为 O(N)，常数时间也比处理单个 HyperLogLog 时要大得多  
 ```
# 返回 ip_20190301 包含的唯一元素的近似数量
127.0.0.1:6379> PFCOUNT ip_20190301
(integer) 4
127.0.0.1:6379> PFADD ip_20190301 "192.168.0.5"
(integer) 1
127.0.0.1:6379> PFCOUNT ip_20190301
(integer) 5
127.0.0.1:6379> PFADD ip_20190302 "192.168.0.1" "192.168.0.6" "192.168.0.7"
(integer) 1
# 返回 ip_20190301 和 ip_20190302 包含的唯一元素的近似数量
127.0.0.1:6379> PFCOUNT ip_20190301 ip_20190302
(integer) 7
```
 ##### PFMERGE 命令
 将多个 HyperLogLog 合并（merge）为一个 HyperLogLog，合并后的 HyperLogLog 的基数接近于所有输入 HyperLogLog 的可见集合（observed set）的并集。时间复杂度是 O(N)，其中 N 为被合并的 HyperLogLog 数量，不过这个命令的常数复杂度比较高  
 命令格式：PFMERGE destkey sourcekey [sourcekey …]，合并得出的 HyperLogLog 会被储存在 destkey 键里面，如果该键并不存在，那么命令在执行之前，会先为该键创建一个空的 HyperLogLog  
 ```
# ip_2019030102 是 ip_20190301 与 ip_20190302 并集
127.0.0.1:6379> PFMERGE ip_2019030102 ip_20190301 ip_20190302
OK
127.0.0.1:6379> PFCOUNT ip_2019030102
(integer) 7
```
 ##### Redis HyperLogLog的应用场景
 鉴于 HyperLogLog 不保存数据内容的特性，所以，它只适用于一些特定的场景。一个最常遇到的场景需要：**计算日活、7日活、月活数据**  
 **分析：**  
 >如果我们通过解析日志，把 ip 信息（或用户 id）放到集合中，例如：HashSet。如果数量不多则还好，但是假如每天访问的用户有几百万。无疑会占用大量的存储空间。且计算月活时，还需要将一个整月的数据放到一个 Set 中，这随时可能导致我们的程序 OOM
 **如果需要统计月活或者更多的数据,那么只需要将日活跃人数合并在进行统计即可**
 ### GEO
 GEO功能在Redis3.2版本提供，支持存储地理位置信息用来实现诸如附近位置、摇一摇这类依赖于地理位置信息的功能.**geo的数据类型为zset**  
 #### GEOADD 命令
 将给定的空间元素（纬度、经度、名字）添加到指定的键里面  
 这些数据会以有序集合的形式被储存在键里面，从而使得像GEORADIUS和GEORADIUSBYMEMBER这样的命令可以在之后通过位置查询取得这些元素  
 命令demo：GEOADD key longitude(经度) latitude(纬度) member(地点名称) \[longitude latitude member ...](**注意:只能先保存经度再是维度的顺序**)  
 命令描述：将指定的地理空间位置（纬度、经度、名称）添加到指定的key中  
 返回值：添加到sorted set元素的数目，但不包括已更新score的元素
 ```
geoadd cityGeo 116.405285 39.904989 "北京"
geoadd cityGeo 121.472644 31.231706 "上海"
```
 #### GEODIST 命令
 返回两个给定位置之间的距离。如果两个位置之间的其中一个不存在， 那么命令返回空值  
 指定单位的参数 unit 必须是以下单位的其中一个:m 表示单位为米、km 表示单位为千米、mi 表示单位为英里、ft 表示单位为英尺(**不指定unit,则默认为m米**)  
 **GEODIST 命令在计算距离时会假设地球为完美的球形，在极限情况下， 这一假设最大会造成 0.5% 的误差**  
 ```
127.0.0.1:6379> geodist cityGeo 北京 上海
"1067597.9668"
127.0.0.1:6379> geodist cityGeo 北京 上海 km
"1067.5980"
```
 #### GEOPOS 命令
 从键里面返回所有给定位置元素的位置（经度和纬度）。因为 GEOPOS 命令接受可变数量的位置元素作为输入， 所以即使用户只给定了一个位置元素， 命令也会返回数组回复。GEOPOS 命令返回一个数组， 数组中的每个项都由两个元素组成： 第一个元素为给定位置元素的经度， 而第二个元素则为给定位置元素的纬度。 当给定的位置元素不存在时， 对应的数组项为空值  
 ```
127.0.0.1:6379> geopos cityGeo 北京
1) 1) "116.40528291463851929"
   2) "39.9049884229125027"
```
 #### GEOHASH 命令
 返回一个或多个位置元素的 Geohash 表示。返回值：一个数组， 数组的每个项都是一个 geohash 。 命令返回的 geohash 的位置与用户给定的位置元素的位置一一对应  
 ```
127.0.0.1:6379> geohash cityGeo 北京
1) "wx4g0b7xrt0"
```
 #### GEORADIUS 命令
 以给定的经纬度为中心， 返回键包含的位置元素当中， 与中心的距离不超过给定最大距离的所有位置元素。范围可以使用以下其中一个单位：m 表示单位为米。km 表示单位为千米。mi 表示单位为英里。ft 表示单位为英尺  
 **在给定以下可选项时， 命令会返回额外的信息:**  
 
     * WITHDIST：在返回位置元素的同时， 将位置元素与中心之间的距离也一并返回。 距离的单位和用户给定的范围单位保持一致
     
     * WITHCOORD：将位置元素的经度和维度也一并返回
     
     * WITHHASH ： 以 52 位有符号整数的形式， 返回位置元素经过原始 geohash 编码的有序集合分值。 这个选项主要用于底层应用或者调试， 实际中的作用并不大
     
  **命令默认返回未排序的位置元素。 通过以下两个参数， 用户可以指定被返回位置元素的排序方式：**
  
     * ASC ： 根据中心的位置， 按照从近到远的方式返回位置元素
     
     * DESC ： 根据中心的位置， 按照从远到近的方式返回位置元素
  在默认情况下， GEORADIUS 命令会返回所有匹配的位置元素。 虽然用户可以使用 COUNT 选项去获取前 N 个匹配元素， 但是因为命令在内部可能会需要对所有被匹配的元素进行处理， 所以在对一个非常大的区域进行搜索时， 即使只使用 COUNT 选项去获取少量元素， 命令的执行速度也可能会非常慢。 但是从另一方面来说， 使用 COUNT 选项去减少需要返回的元素数量， 对于减少带宽来说仍然是非常有用的  
  `georadius cityGeo 116.405285 39.904989 100 km WITHDIST WITHCOORD ASC COUNT 5`
  #### GEORADIUSBYMEMBER 命令
  这个命令和 GEORADIUS 命令一样， 都可以找出位于指定范围内的元素， 但是 GEORADIUSBYMEMBER 的中心点是由给定的位置元素决定的， 而不是像 GEORADIUS 那样， 使用输入的经度和纬度来决定中心点  
  `georadiusbymember cityGeo 北京 100 km WITHDIST WITHCOORD ASC COUNT 5`
  ### BloomFilter
 BloomFilter是一种空间效率的概率型数据结构，由Burton Howard Bloom 1970年提出的。通常用来判断一个元素是否在集合中。具有极高的空间效率，但是会带来假阳性(False positive)的错误  
 **False positive**  
 BloomFilter在判断一个元素在集合中的时候，会出现一定的错误率，这个错误率称为False positive的。通常缩写为fpp  
 **False negatives**  
 BloomFilter判断一个元素不在集合中的时候的错误率。BloomFilter判断该元素不在集合中，则该元素一定不再集合中。故False negatives概率为0
 #### 算法描述
 BloomFilter使用长度为m bit的字节数组，使用k个hash函数  
 增加一个元素: 通过k次hash将元素映射到字节数组中k个位置中，并设置对应位置的字节为1  
 查询元素是否存在: 将元素k次hash得到k个位置，如果对应k个位置的bit是1则认为存在，反之则认为不存在  
 #### BloomFilter命令
 ```
127.0.0.1:6379> bf.add codehole user1
(integer) 1
127.0.0.1:6379> bf.add codehole user2
(integer) 1
127.0.0.1:6379> bf.add codehole user3
(integer) 1
127.0.0.1:6379> bf.exists codehole user1
(integer) 1
127.0.0.1:6379> bf.exists codehole user2
(integer) 1
127.0.0.1:6379> bf.exists codehole user3
(integer) 1
127.0.0.1:6379> bf.exists codehole user4
(integer) 0
127.0.0.1:6379> bf.madd codehole user4 user5 user6
1) (integer) 1
2) (integer) 1
3) (integer) 1
127.0.0.1:6379> bf.mexists codehole user4 user5 user6 user7
1) (integer) 1
2) (integer) 1
3) (integer) 1
4) (integer) 0
```
>bf.reserve创建Filter，语法：[bf.reserve key error_rate initial_size]，需要注意的是：布隆过滤器的initial_size估计的过大，所需要的空间就越大，会浪费空间，估计的过小会影响准确率，因此在使用前一定要估算好元素数量，还需要加上一定的冗余空间以避免实际元素高出预估数量造成误差过大。布隆过滤器的error_rate越小，所需要的空间就会越大，对于不需要过于准确的，error_rate设置的稍大一点也无所谓
 ## Redis删除机制
 Redis在set key的时候，可以额外给一个expire的参数，这是设置过期时间的
 ### 定时删除
 在设置键的过期时间的同时，创建一个定时器 (timer). 让定时器在键的过期时间来临时，立即执行对键的删除操作
 ### 定期删除
 Redis每隔100ms就会随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就将其删除。  
 随机检查过期删除的原因在于，每隔100ms就检查所有的key，会造成巨大的资源消耗
 ### 惰性删除
 定期删除可能会造成某些已经过期的key未被删除，那么当用户请求某个key的时候，Redis会检查此时key是否已经过期，如果已经过期则会删除
 ## 内存淘汰机制
 - volatile-lru:从已被设置了过期的数据集中挑选最近最少使用的进行淘汰
 - volatile-ttl:从已被设置了过期的数据集中选取即将要过期的进行随机淘汰
 - volatile-random:从已被设置了过期的数据集中随机选取数据进行淘汰
 - allkeys-lru:当内存空间不足以容纳新的数据时，从已存在的数据集中选取最少使用的数据进行淘汰
 - allkeys-random：当内存空间不足以容纳新的数据时，从已存在的数据集中随机选取数据进行淘汰
 - no-evicion:禁止驱逐，内存空间不足时报错
 ### 内存淘汰机制 使用规则
    1.如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，则使用 allkeys-lru
    
    2.如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random
 ## Redis持久化机制
 ###快照持久层（RDB-Redis DataBase）
 Redis可以通过快照来获得内存中某个数据在某个时间点的副本.Redis创建快照之后，可以对快照进行备份,可以将快照复制到其他服务器从而创建相同数据的服务器副本，还可以将快照留在原地以便重启时使用  
 save 900 1 在900秒内有一个key发生变化，创建快照  
 save 300 10 在300秒内有十个key发生变化，创建快照  
 save 60 10000 在60秒内有10000个key发生变化，创建快照
 #### 优点
    1.只有一个文件 dump.rdb，方便持久化
    
    2.容灾性好，一个文件可以保存到安全的磁盘
    
    3.性能最大化，fork 子进程来完成写操作，让主进程继续处理命令，所以是IO最大化。使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 redis的高性能
    
    4.相对于数据集大时，比 AOF 的启动效率更高
  #### 缺点
    1.数据安全性低。RDB 是间隔一段时间进行持久化，如果持久化之间 redis 发生故障，会发生数据丢失。所以这种方式更适合数据要求不严谨的时候
 ### AOF(append-only file)持久化
 在默认情况下未开启，在config文件中修改appendOnly为yes即可  
 AOF文件中的保存位置和RDB位置相同，每当有一条对数据进行更改的命令，Redis就会将此命令写入AOF文件中，默认名为appendOnly.aof  
 appendSync always 每次有数据更改的时候就将此命令写入AOF文件，但会降低redis的速度  
 appendSync everysec 每秒同步一次，显示将多个命令写入磁盘（推荐）  
 appendSync no 让操作系统决定同步  
 AOF重写：在执行BGREWRITEAOF时，Redis服务器会维护一个AOF重写缓冲区，该缓冲区会在子进程创建AOF文件期间，记录服务器执行的所有写命令。当进程完成创建AOF文件的工作之后，服务器会将重写缓冲区中所有内容追加到AOF文件中，使得新旧AOF文件中保持一致。
 #### 优点
     1.数据安全，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次命令操作就记录到 aof 文件中一次
     
     2.通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof工具解决数据一致性问题
 ### RDB和AOF的对比
 - aof文件比rdb文件大，且恢复速度慢
 - aof文件比rdb更新频率更高，优先使用aof持久化数据
 - aof文件比rdb更安全
 - rdb性能比aof好
 - 两个都配了应选aof
 ## Redis架构模式
 ### 单机版模式
 ![单机版模式](image/20180928190805373.png)
 缺点：1、内存容量有限2、处理能力有限3、无法高可用
 ### 主从复制
  ![主从复制模式](image/20180928190721645.png)
  redis的复制功能允许用户根据一个Redis服务器例创建任意多个该服务的复制品，其中被复制的主服务器，复制出来的是从服务器。 只要主从服务器之间的网络连接正常，主从服务器两者会具有相同的数据，主服务器就会一直将发生在自己身上的数据更新同步 给从服务器，从而一直保证主从服务器的数据相同。  
  优点：降低master读压力在转交给从库
  缺点：1、无法保证高可用2、没有解决master写压力
  ### 哨兵模式
   ![哨兵模式](image/20180928190913817.png)
   Redis sentinel是一个分布式监控，Redis主从服务器，并在主服务器下线时自动进行故障转移。  
   - 监控：sentinel会不间断的检查主服务器和从服务器是否运行正常
   - 提醒：当被监控的某个redis服务器出现问题时，sentinel可以通过API向管理员或其他应用程序发送通知
   - 自动故障转移：当一个主服务器不能正常工作时，sentinel会自动进行故障转移
   缺点：1、主从模式，却换需要时间可能丢失数据2、没有解决master写的压力
  ## Redis常见问题
  ### 缓存穿透
  一般的缓存系统，都是按照key去缓存查询的，如果不存在对应的value，就应该去后端数据库查询。但是一些恶意的请求会故意查询不存在的key，请求量大的情况下，就会对后端系统造成巨大压力。  
  如何避免：  
  1、对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该key对应的数据insert之后对应缓存  
  2、对一定不存在的key进行过滤，可以把所有可能存在的key放在bitmap里面（**推荐**）
  ### 缓存雪崩
  当服务器重启或大量缓存集中在同一时间段生效，这样在失效的时候，会给后端带来巨大压力，可能导致系统崩溃  
  如何避免：  
  1、在缓存失效之后，通过加锁或者队列来控制读数据库写缓存的线程数量，比如对某一个key只允许一个线程查询数据和写数据，其他线程等等  
  2、做二级缓存，A1为原始缓存，A2为拷贝数据，A1失效可以访问A2  
  3、不同的key设置不同的是失效时间，做到尽量数据时间均衡  
  ### 缓存预热
  当系统刚刚上线的时候，将相关的缓存数据直接加载到缓存系统，这样就可以避免在用户请求的时候，先查询数据库，然后再将数据缓存的问题
  如何避免：  
  1、可以直接写个缓存页面，上线时手工操作一下  
  2、数据量不多时，可以在项目启动时自动加载  
  3、定时刷新缓存  
  ## Memcashe和Redis的区别
  1、Memcashe将数据全保存在内存中，断电后关掉，不能持久化  
  2、Memcashe所有的值类型全是string类型，而redis则是string，hash，list，set，zset  
  3、Redis直接构建了自己的vm机制，因为一般情况下系统调用系统函数，会浪费一定的资源以及时间  
  4、value值不同：Redis可以达到1G，而Memcashe只有1m
  5、Redis速度比Memcashe快很多
  6、Redis支持数据备份
